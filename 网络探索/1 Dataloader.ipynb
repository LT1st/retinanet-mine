{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 读入coco数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import skimage.color\n",
    "import skimage\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDataset(Dataset):\n",
    "    \"\"\"Coco dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, set_name='train2017', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): COCO directory.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir  # COCO的路径\n",
    "        self.set_name = set_name  # 存有图片名称信息的部分路径名\n",
    "        self.transform = transform  # 对于每一个图片，设定某个或某些变换\n",
    "\n",
    "        # COCO函数是pycocotools中的读入图片信息文件并得到其标注（anns），图片类别（catToImgs），总的类别数和名称（cats），\n",
    "        # 数据集基本信息（dataset），每一张图片对应的anns（imgToAnns），图片（imgs）\n",
    "        self.coco      = COCO(os.path.join(self.root_dir, 'annotations', 'instances_' + self.set_name + '.json'))\n",
    "        # self.coco      = COCO('coco/annotations/image_info_test2017.json')\n",
    "        self.image_ids = self.coco.getImgIds()  # 获得所有图片所对应的ID信息\n",
    "\n",
    "        self.load_classes()\n",
    "\n",
    "    def load_classes(self):\n",
    "        # load class names (name -> label) 生成名字到数字的对照表\n",
    "        categories = self.coco.loadCats(self.coco.getCatIds())  # 获得总的categroy数，80个和对应的名称\n",
    "        categories.sort(key=lambda x: x['id'])\n",
    "\n",
    "        self.classes             = {}\n",
    "        self.coco_labels         = {}\n",
    "        self.coco_labels_inverse = {}\n",
    "        for c in categories:\n",
    "            self.coco_labels[len(self.classes)] = c['id']\n",
    "            self.coco_labels_inverse[c['id']] = len(self.classes)\n",
    "            self.classes[c['name']] = len(self.classes)\n",
    "\n",
    "        # also load the reverse (label -> name) 生成数字到名字的对照表\n",
    "        self.labels = {}\n",
    "        for key, value in self.classes.items():\n",
    "            self.labels[value] = key\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img = self.load_image(idx)\n",
    "        annot = self.load_annotations(idx)\n",
    "        sample = {'img': img, 'annot': annot}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def load_image(self, image_index):\n",
    "        image_info = self.coco.loadImgs(self.image_ids[image_index])[0]  # 读入对应图片的基本信息\n",
    "        path       = os.path.join(self.root_dir, 'images', self.set_name, image_info['file_name'])\n",
    "        img = skimage.io.imread(path)  # 用skimage读入图片\n",
    "\n",
    "        if len(img.shape) == 2:  # 如果是灰度图，转化为rgb的图片\n",
    "            img = skimage.color.gray2rgb(img)\n",
    "\n",
    "        return img.astype(np.float32)/255.0  # 图片的数值转化到0～1之间\n",
    "\n",
    "    def load_annotations(self, image_index):\n",
    "        # get ground truth annotations\n",
    "        annotations_ids = self.coco.getAnnIds(imgIds=self.image_ids[image_index], iscrowd=False)\n",
    "        annotations     = np.zeros((0, 5))\n",
    "\n",
    "        # some images appear to miss annotations (like image with id 257034)\n",
    "        if len(annotations_ids) == 0:  # 如果没有标注，直接返回[0,0,0,0,0]\n",
    "            return annotations\n",
    "\n",
    "        # parse annotations\n",
    "        coco_annotations = self.coco.loadAnns(annotations_ids)\n",
    "        for idx, a in enumerate(coco_annotations):\n",
    "\n",
    "            # some annotations have basically no width / height, skip them 有一些注释没有宽和高，则不采用\n",
    "            if a['bbox'][2] < 1 or a['bbox'][3] < 1:\n",
    "                continue\n",
    "\n",
    "            annotation        = np.zeros((1, 5)) # 将annotation记录为前4位为标注框的位置信息，第5位为label信息\n",
    "            annotation[0, :4] = a['bbox']\n",
    "            annotation[0, 4]  = self.coco_label_to_label(a['category_id'])\n",
    "            annotations       = np.append(annotations, annotation, axis=0)\n",
    "\n",
    "        # transform from [x, y, w, h] to [x1, y1, x2, y2] 将[x, y, w, h]信息转换为[x1, y1, x2, y2]的形式\n",
    "        annotations[:, 2] = annotations[:, 0] + annotations[:, 2]\n",
    "        annotations[:, 3] = annotations[:, 1] + annotations[:, 3]\n",
    "\n",
    "        return annotations\n",
    "\n",
    "    def coco_label_to_label(self, coco_label):\n",
    "        return self.coco_labels_inverse[coco_label]\n",
    "\n",
    "\n",
    "    def label_to_coco_label(self, label):\n",
    "        return self.coco_labels[label]\n",
    "\n",
    "    def image_aspect_ratio(self, image_index):\n",
    "        image = self.coco.loadImgs(self.image_ids[image_index])[0]\n",
    "        return float(image['width']) / float(image['height'])\n",
    "\n",
    "    def num_classes(self):\n",
    "        return 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 一些数据增强函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resizer(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample, min_side=608, max_side=1024):\n",
    "        image, annots = sample['img'], sample['annot']\n",
    "\n",
    "        rows, cols, cns = image.shape\n",
    "\n",
    "        smallest_side = min(rows, cols)\n",
    "\n",
    "        # rescale the image so the smallest side is min_side\n",
    "        scale = min_side / smallest_side\n",
    "\n",
    "        # check if the largest side is now greater than max_side, which can happen\n",
    "        # when images have a large aspect ratio\n",
    "        largest_side = max(rows, cols)\n",
    "\n",
    "        if largest_side * scale > max_side:\n",
    "            scale = max_side / largest_side\n",
    "\n",
    "        # resize the image with the computed scale 为了保证长和宽都是32的倍数，在图片的外围补了一圈\n",
    "        image = skimage.transform.resize(image, (int(round(rows*scale)), int(round((cols*scale)))))\n",
    "        rows, cols, cns = image.shape\n",
    "\n",
    "        pad_w = 32 - rows%32\n",
    "        pad_h = 32 - cols%32\n",
    "\n",
    "        new_image = np.zeros((rows + pad_w, cols + pad_h, cns)).astype(np.float32)\n",
    "        new_image[:rows, :cols, :] = image.astype(np.float32)\n",
    "\n",
    "        annots[:, :4] *= scale\n",
    "\n",
    "        return {'img': torch.from_numpy(new_image), 'annot': torch.from_numpy(annots), 'scale': scale}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmenter(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    # 有50%的概率给图片做一个翻转\n",
    "    def __call__(self, sample, flip_x=0.5):\n",
    "\n",
    "        if np.random.rand() < flip_x:\n",
    "            image, annots = sample['img'], sample['annot']\n",
    "            image = image[:, ::-1, :]\n",
    "\n",
    "            rows, cols, channels = image.shape\n",
    "\n",
    "            x1 = annots[:, 0].copy()\n",
    "            x2 = annots[:, 2].copy()\n",
    "            \n",
    "            x_tmp = x1.copy()\n",
    "\n",
    "            annots[:, 0] = cols - x2\n",
    "            annots[:, 2] = cols - x_tmp\n",
    "\n",
    "            sample = {'img': image, 'annot': annots}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(object):\n",
    "    # 按照经验的均值和方差处理了每一个通道上的值\n",
    "    def __init__(self):\n",
    "        self.mean = np.array([[[0.485, 0.456, 0.406]]])\n",
    "        self.std = np.array([[[0.229, 0.224, 0.225]]])\n",
    "\n",
    "    def __call__(self, sample):\n",
    "\n",
    "        image, annots = sample['img'], sample['annot']\n",
    "\n",
    "        return {'img':((image.astype(np.float32)-self.mean)/self.std), 'annot': annots}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 结果展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=10.59s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset_train = CocoDataset('coco', set_name='train2017', transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img: tensor([[[-0.8321, -1.5966, -1.7681],\n",
      "         [-0.8342, -1.5987, -1.7703],\n",
      "         [-0.8499, -1.6147, -1.7862],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.8243, -1.5886, -1.7602],\n",
      "         [-0.8379, -1.6024, -1.7740],\n",
      "         [-0.8504, -1.6153, -1.7867],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.8281, -1.5925, -1.7788],\n",
      "         [-0.8480, -1.6128, -1.7895],\n",
      "         [-0.8511, -1.6160, -1.7874],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]]])\n",
      "annot: tensor([[160.5120, 450.7053, 184.3760, 508.8580,  39.0000],\n",
      "        [359.7840, 228.2913, 415.2387, 247.1267,  73.0000],\n",
      "        [355.5027, 242.8327, 423.2820, 258.7800,  73.0000],\n",
      "        [284.7973, 298.7053, 480.9913, 380.7220,  73.0000],\n",
      "        [ 34.0353, 474.6073, 225.5807, 666.1527,  60.0000],\n",
      "        [214.8140, 458.0013, 395.5673, 533.9000,  69.0000],\n",
      "        [214.7507, 539.4987, 367.6373, 672.7140,  69.0000],\n",
      "        [306.8373, 129.4787, 453.1880, 193.6860,  73.0000],\n",
      "        [347.3707, 256.4113, 421.9647, 272.7767,  73.0000],\n",
      "        [287.0520, 250.2427, 359.1380, 272.0547,  73.0000],\n",
      "        [296.4000, 154.1280, 448.6787, 214.1680,  73.0000]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "temp = dataset_train[10]\n",
    "print('img:', temp['img'])\n",
    "print('annot:', temp['annot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;该dataloader函数返回对应的img和所有的annotation的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
