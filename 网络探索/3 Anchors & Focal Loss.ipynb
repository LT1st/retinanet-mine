{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 先验框Anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;在RetinaNet中，先验框Anchors的设定遵循着以下几个条件：\n",
    "\n",
    "- 从P3到P7,先验框的大小呈金字塔式的增加，从$32^2$到$512^2$（对应`class Anchors()`的`__init__`部分）;\n",
    "- 先验框的长宽比有$\\{1:2,1:1,2:1\\}$这三种对应`class Anchors()`的`__init__`部分）;\n",
    "- 为了让先验框能更好地覆盖所有情况，金子塔每一层的先验框都会进行一个缩放，放大比例分别有$\\{2^0,2^{(1/3)},2^{(2/3)}\\}$对应`class Anchors()`的`__init__`部分）;\n",
    "- 总的来说，每一层都对应有3x3=9个先验框;\n",
    "- 对于每一个先验框，它对应一个长度为数据类别的one-hot向量和一个长度为4的框回归的向量;\n",
    "- 当IoU大于等于0.5时，该先验框会被对应到一个ground truth对象;当IoU小于0.4时，则被定义为背景;当IoU大于等于0.4小于0.5时，则在训练中被忽略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Anchors(nn.Module):\n",
    "    def __init__(self, pyramid_levels=None, strides=None, sizes=None, ratios=None, scales=None):\n",
    "        super(Anchors, self).__init__()\n",
    "\n",
    "        if pyramid_levels is None:  # 对应有5个层级\n",
    "            self.pyramid_levels = [3, 4, 5, 6, 7]\n",
    "        if strides is None:  # 每个层级对应的特征图大小（原图/2^x）\n",
    "            self.strides = [2 ** x for x in self.pyramid_levels]\n",
    "        if sizes is None:  # base_size的大小（即原图/8的区域对应32×32）\n",
    "            self.sizes = [2 ** (x + 2) for x in self.pyramid_levels]\n",
    "        if ratios is None:  # 三种长宽比\n",
    "            self.ratios = np.array([0.5, 1, 2])\n",
    "        if scales is None:  # 三种缩放\n",
    "            self.scales = np.array([2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)])\n",
    "\n",
    "    def forward(self, image):\n",
    "        \n",
    "        image_shape = image.shape[2:]\n",
    "        image_shape = np.array(image_shape)\n",
    "        image_shapes = [(image_shape + 2 ** x - 1) // (2 ** x) for x in self.pyramid_levels]\n",
    "\n",
    "        # compute anchors over all pyramid levels\n",
    "        all_anchors = np.zeros((0, 4)).astype(np.float32)\n",
    "\n",
    "        for idx, p in enumerate(self.pyramid_levels):\n",
    "            # 对某一特定大小的特征图，生成其所有anchor坐标信息\n",
    "            anchors         = generate_anchors(base_size=self.sizes[idx], ratios=self.ratios, scales=self.scales)\n",
    "            # 按照anchor坐标信息，stride数值，计算出实际的anchors所对应的信息（等于做了一个平移）\n",
    "            shifted_anchors = shift(image_shapes[idx], self.strides[idx], anchors)\n",
    "            all_anchors     = np.append(all_anchors, shifted_anchors, axis=0)\n",
    "\n",
    "        all_anchors = np.expand_dims(all_anchors, axis=0)\n",
    "\n",
    "        if torch.cuda.is_available():  # 如果支持GPU，则转换成cuda类型\n",
    "            return torch.from_numpy(all_anchors.astype(np.float32)).cuda()\n",
    "        else:\n",
    "            return torch.from_numpy(all_anchors.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_anchors(base_size=16, ratios=None, scales=None):\n",
    "    \"\"\"\n",
    "    Generate anchor (reference) windows by enumerating aspect ratios X\n",
    "    scales w.r.t. a reference window.\n",
    "    \"\"\"\n",
    "\n",
    "    if ratios is None:\n",
    "        ratios = np.array([0.5, 1, 2])\n",
    "\n",
    "    if scales is None:\n",
    "        scales = np.array([2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)])\n",
    "\n",
    "    # 计算Anchor的总数9\n",
    "    num_anchors = len(ratios) * len(scales)\n",
    "\n",
    "    # initialize output anchors  初始化输出的结果9×4的大小\n",
    "    anchors = np.zeros((num_anchors, 4))\n",
    "\n",
    "    # scale base_size\n",
    "    # 复制成2行，3列 ,即（2，9）\n",
    "    # 转置成（9，2），每行都是一组ratio和scale的组合，比例是base_size的\n",
    "    anchors[:, 2:] = base_size * np.tile(scales, (2, len(ratios))).T\n",
    "\n",
    "    # compute areas of anchors 其实2、3值是一样的\n",
    "    areas = anchors[:, 2] * anchors[:, 3]\n",
    "\n",
    "    # correct for ratios 实际2列上等于anchors[:, 2:]/sqrt（scales）而实际3列上等于anchors[:, 2:]×sqrt（scales）\n",
    "    anchors[:, 2] = np.sqrt(areas / np.repeat(ratios, len(scales)))\n",
    "    anchors[:, 3] = anchors[:, 2] * np.repeat(ratios, len(scales))\n",
    "\n",
    "    # transform from (x_ctr, y_ctr, w, h) -> (x1, y1, x2, y2) 转换anchors的形式\n",
    "    anchors[:, 0::2] -= np.tile(anchors[:, 2] * 0.5, (2, 1)).T\n",
    "    anchors[:, 1::2] -= np.tile(anchors[:, 3] * 0.5, (2, 1)).T\n",
    "\n",
    "    return anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Focal Loss & 框回归子网络的Loss\n",
    "&emsp;Focal Loss仅用于分类子网络上，而整体的loss还包括框回归子网络的loss。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Focal Loss\n",
    "&emsp;Focal Loss是交叉熵损失的改进版本，一个二分类交叉熵可以表示为：\n",
    "$$CE(p,y)=\n",
    "\\begin{cases}\n",
    "-\\log{(p)}& \\text{if}{\\quad}y=1\\\\\n",
    "-\\log{(1-p)}& \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "&emsp;上面公式可以简写成：\n",
    "$$CE(p,y)=CE(p_t)=-\\log{(p_t)}$$\n",
    "&emsp;其中：\n",
    "$$p_t=\n",
    "\\begin{cases}\n",
    "p & \\text{if}{\\quad}y=1\\\\\n",
    "1-p & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "#### $\\alpha$：解决正负样本不平衡\n",
    "&emsp;平衡交叉熵的提出是为了解决正负样本不平衡的问题的。它的原理很简单，为正负样本分配不同的权重比值$\\alpha\\in{[0,1]}$，当$y=1$时取$\\alpha$，为$y=0$时取$1-\\alpha$。我们使用和$p_t$类似的方法将上面$\\alpha$的情况表示为$\\alpha_t$，即:\n",
    "$$\\alpha_t=\n",
    "\\begin{cases}\n",
    "\\alpha & \\text{if}{\\quad}y=1\\\\\n",
    "1-\\alpha & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "&emsp;那么这个$\\alpha\\text{-balanced}$交叉熵损失可以表示为\n",
    "$$CE(p_t)=-\\alpha_t\\log{(p_t)}$$\n",
    "#### $\\gamma$：解决难易样本不平衡\n",
    "&emsp;FL中$\\gamma$的引入是为了解决难易样本不平衡的问题的。图2是FL中example预测概率和loss值之间的关系。其中蓝色曲线是交叉熵（$\\gamma=0$时Focal Loss退化为交叉熵损失）的曲线。\n",
    "<img src=\"jpnoteImages/gamma.png\" width=\"350\" align=\"bottom\"/>\n",
    "&emsp;从曲线中我们可以看出对于一些well-classified examples (easy examples)虽然它们单个example的loss可以收敛到很小，但是由于它们的数量过于庞大，把一些hard example的loss覆盖掉。导致求和之后他们依然会支配整个批次样本的收敛方向。\n",
    "\n",
    "&emsp;一个非常简单的策略是继续缩小easy examples的训练比重。作者的思路很简单，给每个乘以$(1-p_t)^{\\gamma}$。因为easy example的score$p_t$往往接近1，那么$(1-p_t)^{\\gamma}$值会比较小，因此example得到了抑制，相对的hard example得到了放大，例如图中$\\gamma>0$的那四条曲线。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 框回归子网络的Loss\n",
    "&emsp;框回归子网络的Loss中prediction（regression）与ground truth之间的关系与SSD的部分基本一致，比较有区别的地方在于loss的定义形式为如下分段函数的形式（从代码中获得，论文中未详细提及）\n",
    "$$\n",
    "\\text{diff}=|\\text{targets}-\\text{pred}| \\\\\n",
    "\\text{loss}=\n",
    "\\begin{cases}\n",
    "0.5*9*\\text{diff}^2 & \\text{if}{\\quad}\\text{diff}<\\frac{1}{9}\\\\\n",
    "\\text{diff}-\\frac{0.5}{9} & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "&emsp;两个loss对应的代码如下所示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_iou(a, b):  # 用于计算IoU的函数\n",
    "    area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n",
    "\n",
    "    iw = torch.min(torch.unsqueeze(a[:, 2], dim=1), b[:, 2]) - torch.max(torch.unsqueeze(a[:, 0], 1), b[:, 0])\n",
    "    ih = torch.min(torch.unsqueeze(a[:, 3], dim=1), b[:, 3]) - torch.max(torch.unsqueeze(a[:, 1], 1), b[:, 1])\n",
    "\n",
    "    iw = torch.clamp(iw, min=0)\n",
    "    ih = torch.clamp(ih, min=0)\n",
    "\n",
    "    ua = torch.unsqueeze((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), dim=1) + area - iw * ih\n",
    "\n",
    "    ua = torch.clamp(ua, min=1e-8)\n",
    "\n",
    "    intersection = iw * ih\n",
    "\n",
    "    IoU = intersection / ua\n",
    "\n",
    "    return IoU\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    #def __init__(self):\n",
    "\n",
    "    def forward(self, classifications, regressions, anchors, annotations):\n",
    "        alpha = 0.25  # Focal Loss中的alpha和gamma与论文中的一致\n",
    "        gamma = 2.0\n",
    "        batch_size = classifications.shape[0]\n",
    "        classification_losses = []\n",
    "        regression_losses = []\n",
    "\n",
    "        anchor = anchors[0, :, :]\n",
    "\n",
    "        # 重新将anchors的值从左上坐标，右下坐标）转为（中心坐标，宽高）格式\n",
    "        anchor_widths  = anchor[:, 2] - anchor[:, 0]\n",
    "        anchor_heights = anchor[:, 3] - anchor[:, 1]\n",
    "        anchor_ctr_x   = anchor[:, 0] + 0.5 * anchor_widths\n",
    "        anchor_ctr_y   = anchor[:, 1] + 0.5 * anchor_heights\n",
    "\n",
    "        for j in range(batch_size):  # 对于batch_size中的每一张图片，做以下处理\n",
    "\n",
    "            classification = classifications[j, :, :]\n",
    "            regression = regressions[j, :, :]\n",
    "\n",
    "            bbox_annotation = annotations[j, :, :]\n",
    "            bbox_annotation = bbox_annotation[bbox_annotation[:, 4] != -1]  # 取bbox_annotation的值不为-1的框\n",
    "            \n",
    "            classification = torch.clamp(classification, 1e-4, 1.0 - 1e-4)  # 将类别数值规范到[1e-4, 1.0 - 1e-4]，避免取对数时候出现问题\n",
    "\n",
    "            if bbox_annotation.shape[0] == 0:  # 只计算classification_losses，不计算regression_losses，并执行完后跳过\n",
    "                if torch.cuda.is_available():  # 分有没有GPU的两种情况\n",
    "                    alpha_factor = torch.ones(classification.shape).cuda() * alpha\n",
    "\n",
    "                    alpha_factor = 1. - alpha_factor\n",
    "                    focal_weight = classification\n",
    "                    focal_weight = alpha_factor * torch.pow(focal_weight, gamma)\n",
    "\n",
    "                    bce = -(torch.log(1.0 - classification))\n",
    "\n",
    "                    # cls_loss = focal_weight * torch.pow(bce, gamma)\n",
    "                    cls_loss = focal_weight * bce\n",
    "                    classification_losses.append(cls_loss.sum())  # 有classification_losses\n",
    "                    regression_losses.append(torch.tensor(0).float())  # 但regression_losses为常数0\n",
    "                    \n",
    "                else:\n",
    "                    alpha_factor = torch.ones(classification.shape) * alpha\n",
    "\n",
    "                    alpha_factor = 1. - alpha_factor\n",
    "                    focal_weight = classification\n",
    "                    focal_weight = alpha_factor * torch.pow(focal_weight, gamma)\n",
    "\n",
    "                    bce = -(torch.log(1.0 - classification))\n",
    "\n",
    "                    # cls_loss = focal_weight * torch.pow(bce, gamma)\n",
    "                    cls_loss = focal_weight * bce\n",
    "                    classification_losses.append(cls_loss.sum())\n",
    "                    regression_losses.append(torch.tensor(0).float())\n",
    "                    \n",
    "                continue\n",
    "\n",
    "            # 接着计算所有anchor与真实框的IOU大小\n",
    "            IoU = calc_iou(anchors[0, :, :], bbox_annotation[:, :4])  # num_anchors x num_annotations\n",
    "\n",
    "            # 找到所有anchor IOU最大的真实框的索引以及该IOU大小\n",
    "            IoU_max, IoU_argmax = torch.max(IoU, dim=1)  # num_anchors x 1\n",
    "\n",
    "            #import pdb\n",
    "            #pdb.set_trace()\n",
    "\n",
    "            # 开始计算两个子网络的损失\n",
    "            targets = torch.ones(classification.shape) * -1  # (anchor_nums,class_num),初始全为-1\n",
    "\n",
    "            if torch.cuda.is_available():  # 判断是否有GPU，有则用\n",
    "                targets = targets.cuda()\n",
    "\n",
    "            targets[torch.lt(IoU_max, 0.4), :] = 0  # IOU<0.4为负样本，记为0\n",
    "\n",
    "            positive_indices = torch.ge(IoU_max, 0.5)  # IOU>=0.5为正样本，找到index\n",
    "\n",
    "            num_positive_anchors = positive_indices.sum()  # 正样本个数\n",
    "\n",
    "            assigned_annotations = bbox_annotation[IoU_argmax, :]  # 通过IoU_argmax找到对应的实际annotations为哪一个（anchor_nums,4）\n",
    "\n",
    "            # compute the loss for classification 计算分类子网络的损失\n",
    "            targets[positive_indices, :] = 0  # 将targets中正样本对应的类别全赋值为0\n",
    "            targets[positive_indices, assigned_annotations[positive_indices, 4].long()] = 1  # 通过查assigned_annotations第5位上的标签信息，实现one-hot的效果\n",
    "\n",
    "            if torch.cuda.is_available():  # 判断是否有GPU，有则用\n",
    "                alpha_factor = torch.ones(targets.shape).cuda() * alpha\n",
    "            else:\n",
    "                alpha_factor = torch.ones(targets.shape) * alpha\n",
    "\n",
    "            # torch.where的作用是[1]满足则[2]，不满足则[3]\n",
    "            alpha_factor = torch.where(torch.eq(targets, 1.), alpha_factor, 1. - alpha_factor)  # 正样本用alpha，负样本用1-alpha\n",
    "            focal_weight = torch.where(torch.eq(targets, 1.), 1. - classification, classification)  # 正样本用1-classification ，负样本用classification\n",
    "            focal_weight = alpha_factor * torch.pow(focal_weight, gamma)  # 对应文中的alpha×(1-classification)^gamma\n",
    "\n",
    "            bce = -(targets * torch.log(classification) + (1.0 - targets) * torch.log(1.0 - classification))  # 普通的Balanced Cross Entropy公式\n",
    "\n",
    "            # cls_loss = focal_weight * torch.pow(bce, gamma)\n",
    "            cls_loss = focal_weight * bce  # 将focal_weight与普通的Balanced Cross Entropy就可以得到Focal Loss\n",
    "\n",
    "            if torch.cuda.is_available():  # 如果targets不存在（为-1），此时的cls_loss置为常数0\n",
    "                cls_loss = torch.where(torch.ne(targets, -1.0), cls_loss, torch.zeros(cls_loss.shape).cuda())\n",
    "            else:\n",
    "                cls_loss = torch.where(torch.ne(targets, -1.0), cls_loss, torch.zeros(cls_loss.shape))\n",
    "\n",
    "            classification_losses.append(cls_loss.sum()/torch.clamp(num_positive_anchors.float(), min=1.0))  # 将classification loss求并除以num_positive_anchors的数目\n",
    "\n",
    "            # compute the loss for regression 计算回归框子函数的损失\n",
    "\n",
    "            if positive_indices.sum() > 0:  # 当存在positive_indices的时候进行计算\n",
    "                assigned_annotations = assigned_annotations[positive_indices, :]  # 找到当存在positive_indices的时候进行计算对应的assigned_annotations\n",
    "\n",
    "                # 找到positive_indices对应的anchors的四个值\n",
    "                anchor_widths_pi = anchor_widths[positive_indices]\n",
    "                anchor_heights_pi = anchor_heights[positive_indices]\n",
    "                anchor_ctr_x_pi = anchor_ctr_x[positive_indices]\n",
    "                anchor_ctr_y_pi = anchor_ctr_y[positive_indices]\n",
    "\n",
    "                # 重新将assigned_annotations的值从左上坐标，右下坐标）转为（中心坐标，宽高）格式\n",
    "                gt_widths  = assigned_annotations[:, 2] - assigned_annotations[:, 0]\n",
    "                gt_heights = assigned_annotations[:, 3] - assigned_annotations[:, 1]\n",
    "                gt_ctr_x   = assigned_annotations[:, 0] + 0.5 * gt_widths\n",
    "                gt_ctr_y   = assigned_annotations[:, 1] + 0.5 * gt_heights\n",
    "\n",
    "                # clip widths to 1  最小框的长宽不会小于1个像素点\n",
    "                gt_widths  = torch.clamp(gt_widths, min=1)\n",
    "                gt_heights = torch.clamp(gt_heights, min=1)\n",
    "\n",
    "                # 结合assigned_annotations（实际的）和anchor计算regression应该预测的值为多少（这部分和SSD的过程一致）\n",
    "                targets_dx = (gt_ctr_x - anchor_ctr_x_pi) / anchor_widths_pi\n",
    "                targets_dy = (gt_ctr_y - anchor_ctr_y_pi) / anchor_heights_pi\n",
    "                targets_dw = torch.log(gt_widths / anchor_widths_pi)\n",
    "                targets_dh = torch.log(gt_heights / anchor_heights_pi)\n",
    "\n",
    "                targets = torch.stack((targets_dx, targets_dy, targets_dw, targets_dh))\n",
    "                targets = targets.t()\n",
    "\n",
    "                if torch.cuda.is_available():  # 将targets的值做一个扩大，应该是为了扩大regression输出值拟合的范围\n",
    "                    targets = targets/torch.Tensor([[0.1, 0.1, 0.2, 0.2]]).cuda()\n",
    "                else:\n",
    "                    targets = targets/torch.Tensor([[0.1, 0.1, 0.2, 0.2]])\n",
    "\n",
    "                negative_indices = 1 + (~positive_indices)  # 无用代码\n",
    "\n",
    "                regression_diff = torch.abs(targets - regression[positive_indices, :])  # 取实际与预测的相对误差\n",
    "\n",
    "                regression_loss = torch.where(\n",
    "                    torch.le(regression_diff, 1.0 / 9.0),\n",
    "                    0.5 * 9.0 * torch.pow(regression_diff, 2),\n",
    "                    regression_diff - 0.5 / 9.0\n",
    "                )  # 分段式的loss，小于1/9时，为二范数，大于1/9时为y=x+c\n",
    "                regression_losses.append(regression_loss.mean())\n",
    "            else:\n",
    "                if torch.cuda.is_available():\n",
    "                    regression_losses.append(torch.tensor(0).float().cuda())\n",
    "                else:\n",
    "                    regression_losses.append(torch.tensor(0).float())\n",
    "\n",
    "        # 分别返回classification_losses和regression_losses\n",
    "        return torch.stack(classification_losses).mean(dim=0, keepdim=True), torch.stack(regression_losses).mean(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 其他功能性函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBoxTransform(nn.Module):\n",
    "    '''\n",
    "    该函数的作用在于将class FocalLoss中的\n",
    "        if torch.cuda.is_available():  # 将targets的值做一个扩大，应该是为了扩大regression输出值拟合的范围\n",
    "            targets = targets/torch.Tensor([[0.1, 0.1, 0.2, 0.2]]).cuda()\n",
    "        else:\n",
    "            targets = targets/torch.Tensor([[0.1, 0.1, 0.2, 0.2]])\n",
    "    部分的变换变回去，并结合Anchors和regression的值计算出实际相对于左上角的box位置\n",
    "    '''\n",
    "    def __init__(self, mean=None, std=None):\n",
    "        super(BBoxTransform, self).__init__()\n",
    "        if mean is None:\n",
    "            if torch.cuda.is_available():\n",
    "                self.mean = torch.from_numpy(np.array([0, 0, 0, 0]).astype(np.float32)).cuda()\n",
    "            else:\n",
    "                self.mean = torch.from_numpy(np.array([0, 0, 0, 0]).astype(np.float32))\n",
    "\n",
    "        else:\n",
    "            self.mean = mean\n",
    "        if std is None:\n",
    "            if torch.cuda.is_available():\n",
    "                self.std = torch.from_numpy(np.array([0.1, 0.1, 0.2, 0.2]).astype(np.float32)).cuda()\n",
    "            else:\n",
    "                self.std = torch.from_numpy(np.array([0.1, 0.1, 0.2, 0.2]).astype(np.float32))\n",
    "        else:\n",
    "            self.std = std\n",
    "\n",
    "    def forward(self, boxes, deltas):\n",
    "\n",
    "        widths  = boxes[:, :, 2] - boxes[:, :, 0]\n",
    "        heights = boxes[:, :, 3] - boxes[:, :, 1]\n",
    "        ctr_x   = boxes[:, :, 0] + 0.5 * widths\n",
    "        ctr_y   = boxes[:, :, 1] + 0.5 * heights\n",
    "\n",
    "        dx = deltas[:, :, 0] * self.std[0] + self.mean[0]\n",
    "        dy = deltas[:, :, 1] * self.std[1] + self.mean[1]\n",
    "        dw = deltas[:, :, 2] * self.std[2] + self.mean[2]\n",
    "        dh = deltas[:, :, 3] * self.std[3] + self.mean[3]\n",
    "\n",
    "        pred_ctr_x = ctr_x + dx * widths\n",
    "        pred_ctr_y = ctr_y + dy * heights\n",
    "        pred_w     = torch.exp(dw) * widths\n",
    "        pred_h     = torch.exp(dh) * heights\n",
    "\n",
    "        pred_boxes_x1 = pred_ctr_x - 0.5 * pred_w\n",
    "        pred_boxes_y1 = pred_ctr_y - 0.5 * pred_h\n",
    "        pred_boxes_x2 = pred_ctr_x + 0.5 * pred_w\n",
    "        pred_boxes_y2 = pred_ctr_y + 0.5 * pred_h\n",
    "\n",
    "        pred_boxes = torch.stack([pred_boxes_x1, pred_boxes_y1, pred_boxes_x2, pred_boxes_y2], dim=2)\n",
    "\n",
    "        return pred_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
